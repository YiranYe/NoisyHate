{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from diverse_perturb import PerturbationCluster, PerturbationGenerator\n",
    "\n",
    "full_df = pd.read_pickle(\"/Users/yeyiran/PycharmProjects/Norm_Pert/bert_important_word_list.pkl\") \n",
    "\n",
    "with open('/Users/yeyiran/PycharmProjects/Norm_Pert/hard_pert_test.json') as hard_pert_f:\n",
    "    old_hard_pert = json.load(hard_pert_f)\n",
    "\n",
    "with open('/Users/yeyiran/PycharmProjects/Norm_Pert/easy_pert_test.json') as easy_pert_f:\n",
    "    easy_pert = json.load(easy_pert_f)\n",
    "\n",
    "\n",
    "with open('/Users/yeyiran/PycharmProjects/Norm_Pert/rule_pert_dict.json') as rule_pert_f:\n",
    "    rule_pert = json.load(rule_pert_f)\n",
    "\n",
    "hard_pert = defaultdict(list)\n",
    "for k,v in old_hard_pert.items():\n",
    "    for value in v:\n",
    "        if value.lower() != k:\n",
    "            hard_pert[k].append(value)\n",
    "\n",
    "\n",
    "pert_total = defaultdict(set)\n",
    "for k,v in old_hard_pert.items():\n",
    "    for val in v:\n",
    "        pert_total[k].add(val)\n",
    "\n",
    "for k,v in easy_pert.items():\n",
    "    for val in v:\n",
    "        pert_total[k].add(val)\n",
    "\n",
    "for k,v in rule_pert.items():\n",
    "    for val in v[0]:\n",
    "        pert_total[k].add(val)\n",
    "\n",
    "\n",
    "Cluster = PerturbationCluster(pert_dict = pert_total, discard_func=['placeholder'])\n",
    "cluster_dict = Cluster.classify()\n",
    "attribute_list = Cluster.get_attribute_list()\n",
    "Generator = PerturbationGenerator(cluster_dict,attribute_list, initial_cnt=[1,1,1,1,1,1])\n",
    "Generator.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>...</th>\n",
       "      <th>latino</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>clean</th>\n",
       "      <th>perturbed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-08 06:10:57.978558+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5918568.0</td>\n",
       "      <td>375121.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>hit em low</td>\n",
       "      <td>hiT em low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-03-08 16:41:59.402377+00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317616.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>there are some incredibly stupid people on thi...</td>\n",
       "      <td>there are some incredibly stpid people on this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-18 22:58:40.549659+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>390678.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>stupidity is increasing exponentially on plane...</td>\n",
       "      <td>stupidityI is increasing exponentially on plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-09 13:32:57.653593+00</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5924299.0</td>\n",
       "      <td>375710.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>what a moron</td>\n",
       "      <td>what a morooon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-22 19:54:31.719790+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>157976.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>the author of this little piece of trashy fict...</td>\n",
       "      <td>the author of this little piece of trashI fict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-21 06:40:09.220587+00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5809395.0</td>\n",
       "      <td>368704.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>for justice we need the death penalty in a cas...</td>\n",
       "      <td>for justice we need the deaath penalty in a ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-12 21:30:11.686130+00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37721.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>this is pretty much exactly how i feel damn</td>\n",
       "      <td>this is pretty much exactly how i feel daaammnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-19 03:05:38.751272+00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>368077.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>a controversial rat</td>\n",
       "      <td>a controversial Ratt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-11 16:44:36.203924+00</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>376464.0</td>\n",
       "      <td>approved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>more leftist insanity</td>\n",
       "      <td>more leftist 1nsanity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-08 17:17:32.951182+00</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5732291.0</td>\n",
       "      <td>364186.0</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>or the fat lady to sing</td>\n",
       "      <td>or the FaT lady to sing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2120 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     created_date  publication_id  parent_id  article_id  \\\n",
       "0   2017-09-08 06:10:57.978558+00            54.0  5918568.0    375121.0   \n",
       "0   2017-03-08 16:41:59.402377+00            13.0        NaN    317616.0   \n",
       "0   2017-10-18 22:58:40.549659+00            54.0        NaN    390678.0   \n",
       "0   2017-09-09 13:32:57.653593+00           102.0  5924299.0    375710.0   \n",
       "0   2016-12-22 19:54:31.719790+00            54.0        NaN    157976.0   \n",
       "..                            ...             ...        ...         ...   \n",
       "0   2017-08-21 06:40:09.220587+00            21.0  5809395.0    368704.0   \n",
       "0   2016-02-12 21:30:11.686130+00             6.0        NaN     37721.0   \n",
       "0   2017-08-19 03:05:38.751272+00            21.0        NaN    368077.0   \n",
       "0   2017-09-11 16:44:36.203924+00           105.0        NaN    376464.0   \n",
       "0   2017-08-08 17:17:32.951182+00            54.0  5732291.0    364186.0   \n",
       "\n",
       "      rating  funny  wow  sad  likes  disagree  ...  latino  \\\n",
       "0   approved    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    1.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    4.0       0.0  ...     NaN   \n",
       "0   rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    1.0       2.0  ...     NaN   \n",
       "..       ...    ...  ...  ...    ...       ...  ...     ...   \n",
       "0   rejected    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   approved    0.0  0.0  0.0    0.0       0.0  ...     NaN   \n",
       "0   rejected    0.0  0.0  0.0    0.0       0.0  ...     0.0   \n",
       "\n",
       "    other_race_or_ethnicity  physical_disability  \\\n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "..                      ...                  ...   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       NaN                  NaN   \n",
       "0                       0.0                  0.0   \n",
       "\n",
       "    intellectual_or_learning_disability  psychiatric_or_mental_illness  \\\n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "..                                  ...                            ...   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   NaN                            NaN   \n",
       "0                                   0.0                            0.0   \n",
       "\n",
       "    other_disability  identity_annotator_count  toxicity_annotator_count  \\\n",
       "0                NaN                       0.0                      65.0   \n",
       "0                NaN                       0.0                      52.0   \n",
       "0                NaN                       0.0                      10.0   \n",
       "0                NaN                       0.0                      64.0   \n",
       "0                NaN                       0.0                      64.0   \n",
       "..               ...                       ...                       ...   \n",
       "0                NaN                       0.0                      10.0   \n",
       "0                NaN                       0.0                      10.0   \n",
       "0                NaN                       0.0                      10.0   \n",
       "0                NaN                       0.0                      10.0   \n",
       "0                0.0                       6.0                      10.0   \n",
       "\n",
       "                                                clean  \\\n",
       "0                                          hit em low   \n",
       "0   there are some incredibly stupid people on thi...   \n",
       "0   stupidity is increasing exponentially on plane...   \n",
       "0                                        what a moron   \n",
       "0   the author of this little piece of trashy fict...   \n",
       "..                                                ...   \n",
       "0   for justice we need the death penalty in a cas...   \n",
       "0         this is pretty much exactly how i feel damn   \n",
       "0                                 a controversial rat   \n",
       "0                               more leftist insanity   \n",
       "0                             or the fat lady to sing   \n",
       "\n",
       "                                            perturbed  \n",
       "0                                          hiT em low  \n",
       "0   there are some incredibly stpid people on this...  \n",
       "0   stupidityI is increasing exponentially on plan...  \n",
       "0                                      what a morooon  \n",
       "0   the author of this little piece of trashI fict...  \n",
       "..                                                ...  \n",
       "0   for justice we need the deaath penalty in a ca...  \n",
       "0     this is pretty much exactly how i feel daaammnn  \n",
       "0                                a controversial Ratt  \n",
       "0                               more leftist 1nsanity  \n",
       "0                             or the FaT lady to sing  \n",
       "\n",
       "[2120 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_NUM_OF_PERT = 1\n",
    "THRESHOLD = 0.5\n",
    "# num_of_idx = 0\n",
    "cols = ['created_date', 'publication_id',\n",
    "       'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes',\n",
    "       'disagree', 'toxicity', 'severe_toxicity', 'obscene', 'sexual_explicit',\n",
    "       'identity_attack', 'insult', 'threat', 'male', 'female', 'transgender',\n",
    "       'other_gender', 'heterosexual', 'homosexual_gay_or_lesbian', 'bisexual',\n",
    "       'other_sexual_orientation', 'christian', 'jewish', 'muslim', 'hindu',\n",
    "       'buddhist', 'atheist', 'other_religion', 'black', 'white', 'asian',\n",
    "       'latino', 'other_race_or_ethnicity', 'physical_disability',\n",
    "       'intellectual_or_learning_disability', 'psychiatric_or_mental_illness',\n",
    "       'other_disability', 'identity_annotator_count',\n",
    "       'toxicity_annotator_count']\n",
    "empty_dict = {col:[] for col in cols}\n",
    "empty_dict['clean'] = []\n",
    "empty_dict['perturbed'] = []\n",
    "result = pd.DataFrame.from_dict(data=empty_dict)\n",
    "for idx,row in full_df.iterrows():\n",
    "    # if not num_of_idx % 1000:\n",
    "    #     print(num_of_idx, result.shape)\n",
    "    # num_of_idx += 1\n",
    "    clean = row['clean']\n",
    "    word_list = clean.split()\n",
    "    diff_weights = row['diff_weight_list']\n",
    "    weight, location = diff_weights[0]\n",
    "    if weight > THRESHOLD:\n",
    "        pertbed_list = set()\n",
    "        for i in range(MAX_NUM_OF_PERT):\n",
    "            pert = Generator.pert_one(word_list[location])\n",
    "            if pert:\n",
    "                pertbed_list.add(' '.join(word_list[:location] + [pert] + word_list[location+1:]))\n",
    "\n",
    "        for p in pertbed_list:\n",
    "            cur_dict = {col:row[col] for col in cols}\n",
    "            cur_dict['clean'] = [clean]\n",
    "            cur_dict['perturbed'] = [p]\n",
    "            result = pd.concat([result, pd.DataFrame(data=cur_dict)])\n",
    "\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowercase_uppercase: 475\n",
      "interesting_lowercase_uppercase: 230\n",
      "emoticons: 0\n",
      "repeat_char: 717\n",
      "abbr: 373\n",
      "special_character: 325\n"
     ]
    }
   ],
   "source": [
    "print(Generator.get_cnt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.78\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from googleapiclient import discovery\n",
    "from config import PERSPECTIVE_API_KEY\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "print(PERSPECTIVE_API_KEY)\n",
    "\n",
    "client = discovery.build(\n",
    "    \"commentanalyzer\",\n",
    "    \"v1alpha1\",\n",
    "    developerKey=PERSPECTIVE_API_KEY,\n",
    "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "    static_discovery=False,\n",
    ")\n",
    "\n",
    "def perspective_acc(data_list,t=0.5):\n",
    "    denominator = 0\n",
    "    total = 0\n",
    "    # for sentence in data_list:\n",
    "    for i in range(len(data_list)):\n",
    "        sentence = data_list[i]\n",
    "        time.sleep(2)\n",
    "        total += 1\n",
    "        # print(total)\n",
    "\n",
    "        analyze_request = {\n",
    "            'comment': { 'text': sentence },\n",
    "            'requestedAttributes': {'TOXICITY': {}},\n",
    "            'languages': [\"en\"],\n",
    "            'doNotStore':True\n",
    "        }\n",
    "        \n",
    "        response = client.comments().analyze(body=analyze_request).execute()\n",
    "        score = 0 if response[\"attributeScores\"][\"TOXICITY\"][\"spanScores\"][0][\"score\"][\"value\"] < t else 1\n",
    "        if score:\n",
    "            denominator += 1\n",
    "    return f\"acc: {round(denominator/total,2)}\"\n",
    "\n",
    "# print(perspective_acc(list(result['perturbed']))) # 0.62\n",
    "print(perspective_acc(list(result['clean']))) # 0.78\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n",
      "(212, 45)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, os.path\n",
    "batch_size = 10\n",
    "nparr = np.array_split(result, batch_size)\n",
    "for i in range(batch_size):\n",
    "    # cur = pd.concat([nparr[i], control], ignore_index=True)\n",
    "    cur = nparr[i]\n",
    "    path = f\"batch_diverse/batch_{i}/\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    cur.to_csv(path + \"/raw.csv\", index=False)\n",
    "    print(cur.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"diverse_pert_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ebd1281c5f5acee8a7f8a313b2ca9c6213b17a23ada965c46f901f6b2a7edb99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
